\documentclass[conference]{IEEEtran}


\usepackage[utf8]{inputenc}
\usepackage[x11names]{xcolor}

\usepackage[np]{numprint}

\definecolor{linkcolor}{RGB}{36,113,163}
\definecolor{citecolor}{RGB}{17,122,101}
\definecolor{urlcolor}{RGB}{148,39,38}

\usepackage[
    colorlinks,
    linkcolor=linkcolor,
    citecolor=citecolor,
    urlcolor=urlcolor
]{hyperref}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{amsmath, amsfonts}

\usepackage{lipsum}

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing, patterns}
\usetikzlibrary{calc, backgrounds}

\usepackage{xspace}

\usepackage{listings}
\usepackage{cleveref}

\lstset{
    basicstyle=\ttfamily,
    keywordstyle={[1]\color{Blue4}\bfseries}, % keywords style
    % keywordstyle={[2]\color{Pink4}}, % type style
    % keywordstyle={[3]\color{OrangeRed3}}, % function style
    % literate =
    %     {=>}{{=>}}2
    %     {/=}{{/=}}2,
    commentstyle=\itshape\color{gray}
}

\def\spark#1{\lstinline[language=Ada]{#1}}

\usepackage{todonotes}
%\def\todo#1{\textcolor{red}{[#1]}}

\def\state#1{\textsf{\MakeUppercase{#1}}\xspace}
\def\sclosed{\state{closed}}
\def\ssynsent{\state{syn-sent}}
\def\ssynrcv{\state{syn-rcvd}}
\def\slisten{\state{listen}}
\def\sestab{\state{established}}
\def\sfwone{\state{fin-wait-1}}
\def\sfwtwo{\state{fin-wait-2}}
\def\sclosing{\state{closing}}
\def\sclosew{\state{close-wait}}
\def\slastack{\state{last-ack}}
\def\stimewait{\state{time-wait}}

\def\flag#1{\textsf{#1}\xspace}
\def\syn{\flag{SYN}}
\def\ack{\flag{ACK}}
\def\rst{\flag{RST}}
\def\fin{\flag{FIN}}

\let\code\texttt

\begin{document}

\title{Layered Formal Verification of an Industrial TCP/IP Stack}

\author{%
\IEEEauthorblockN{Guillaume Cluzel}
\IEEEauthorblockA{\textit{AdaCore \& ENS de Lyon}}
\and
\IEEEauthorblockN{Kyriakos Georgious}
\IEEEauthorblockA{\textit{AdaCore \& University of Bristol}}
\and
\IEEEauthorblockN{Yannick Moy}
\IEEEauthorblockA{\textit{AdaCore}}
\and
\IEEEauthorblockN{Clément Zeller}
\IEEEauthorblockA{\textit{Oryx Embedded}}
}

\maketitle

\begin{abstract}
\todo{Write the abstract.}
\end{abstract}

\begin{IEEEkeywords}
Network protocols,
deductive verification.
\end{IEEEkeywords}

\section{Introduction}

By 2030 it is estimated that one trillion Internet of Things (IoT) devices will be deployed and be part of every aspect of our daily life~\cite{IoT_route:ARM_white_paper}. At the same time, it is made evident that security for such systems is a major challenge~\cite{Sec_IoT_Challenges:paper,Cyber_Systems_security:paper}. Any vulnerability in software libraries that are widely used by embedded systems can potentially open the door for compromising the security of billions of deployed IoT devices. In 2019, critical security vulnerabilities were discovered in a TCP implementation that has been used potentially by billions of IoT devices for more than 13 years \cite{zero_days_vuln:ARMIS_white_paper}, with some of them even allowing remote code execution.

Networking communication models define the processes of transferring information from one network component to another. Currently, the two most popular networking communication models are the TCP/IP (Transmission Control Protocol/Internet Protocol) \cite{TCP_IP:ietf_tutorial} and the OSI (Open System Interconnection) \cite{ISO:35.100} models. Layering is an essential design requirement for both models to achieve modularity, flexibility, and abstraction. Applications that only need to use the lower levels' functionality can drop all the unnecessary upper levels. \Cref{Fig:TcpStack} shows the various layers of the OSI model. Each layer supports a wide range of protocols that are compatible with the layer's specifications. The lowest layers, bottom layers in \Cref{Fig:TcpStack}, are more hardware-oriented, while the top layers are more software-specific. While the \emph{application} level has a wide range of protocols that can be used depending on the application specification, the \emph{transport} layer is heavily dependent on the two dominant protocols: Transmission Control Protocol (TCP) and User Datagram Protocol (UDP). Today, almost every networking application, including IoT devices, is using either the TCP or the UDP protocols to traffic data between the Network and the Application layers. %Thus, the reliability, assurance, and security of these protocols are of paramount importance for critical applications.

\input{OryxStack.tex}

Existing research deals with formally verifying several protocols TCP/IP stack levels. For example, the work in \emph{miTLS} \cite{bhargavan2013implementing} formally verifies an SSL/TLS protocol implementation, and the work in \cite{Reiher_2020} uses a technology called RecordFlux to safely parse data segments. Given the reliance of the other software-level protocols on the TCP protocol, formalizing the its specification and verifying its implementation is critical. Achieving these two goals in practice is challenging. This is mainly because TCP's specification, \cite{rfc793}, is written in English rather than any formal language, leaving many parts underspecified. Moreover, the TCP protocol is inherently concurrent, making it complex to specify and verify. Previous work focused on formalizing the protocol to either prove key properties \cite{smith1996formal} or fully verify the TCP protocol's specifications \cite{ridge2008rigorous} using the HOL proof assistant tool. While for the later work, the authors claim that it is possible from their formalization to extract an actual implementation in Haskell, this has not been achieved yet. At this point of writing, we are not aware of any formally verified TCP protocol implementation.


In this paper, we take a practical approach, where the security of an existing TCP/IP stack implementation written in ANSI C programming language is incrementally enhanced by replacing parts of its code with formally verified code in SPARK \cite{mccormick_chapin_2015}. SPARK 2014 is a programming language designed as a subset of the Ada language to produce highly reliable software through formal verification. For this work, the CycloneTCP, a professional-grade embedded TCP/IP library developed by the Oryx Embedded company \cite{CycloneTCP}. \Cref{Fig:TcpStack} shows the protocols supported by the library. This work focuses on the TCP and socket components of the stack. The library's TCP implementation is meant to conform with the RFC 793 protocol specifications \cite{rfc793}. The quality of the CycloneTCP is acknowledged by the AMNESIA:33 report \cite{AMNESIA33}, which classifies it as one of the most resilient TCP/IP stack. By using as a starting point such a well-tested and widely used TCP/IP implementation, the IoT industry can have an immediate benefit by adopting this work's security-enhanced version of the CycloneTCP library. 

\todo[inline]{KG:pending contributions list and fixing the next paragraph. Will be fixed when the rest of the paper is finalized.}

We present the TCP protocol in section~\ref{sec:TCP} and then briefly the
chosen stack, the Oryx Embedded one, in section~\ref{sec:stack}
before presenting the specification techniques used in section~\ref{sec:spec}
and then in sections~\ref{sec:verif} and~\ref{sec:API} we explain how we
formally implemented in SPARK the TCP user functions and how we hardened the
user's API. Finally we end in section~\ref{sec:results} by showing the results
of our work.

\section{Overview of the TCP protocol specification}
\label{sec:TCP}

\input{Automaton.tex}

TCP is a connection-oriented protocol; a connection between the sender and the receiver must be established before transmitting any data. Furthermore, TCP is a reliable protocol since it guarantees the delivery of all the messages and that they are delivered in the order, they were sent. It also provides error-checking mechanisms to discard and recover any corrupted data.

%\subsection{TCP state machine}

Generally, every TCP communication session will go through the following three phases (if no error occurs): 1)~opening the connection, 2)~sending and receiving the data, and 3)~closing the connection. The behaviour of the three-phase communication can be described by the state machine given in \cref{Fig:statemachine}. An edge represents a state transition. A transition is either triggered by an explicit action, stated in italics format on the label's edge, for example, \textit{Close}, or is triggered by the arrival of a specific flag/s. An edge-label in the format of $\frac{\ \ x \ \ }{\ \ y \ \ }$ represents the associated flags transmitted with each transition, where $x$ is either send or receive and $y$ refers to the actual flag/s transmitted in response to the action that caused the state transition. An explicit action is either a user-triggered action (through the user's API) or an automatically performed action triggered by a timeout event. The flags are embedded in the header section of a transmitted segment and can be one of the following:
\begin{itemize}
\item \ack: the last message received by the sender is acknowledged.
\item \syn: this flag is sent to establish a connection.
\item \fin: this flag is sent to close the connection.
\item \rst: this flag is sent to reset the connection, often when an error
occurred on one or the other side.
\end{itemize}

The state machine in \cref{Fig:statemachine} does not represent the complete protocol specification; for example, it does not reflect error conditions or any actions which are not connected with the state changes. Instead, it gives an overview of all the possible states a TCP connection could reach over its lifetime. Each state has a meaning. \slisten represents waiting for a connection request from any remote TCP and port. \ssynsent and \ssynrcv represent the initialization of the connection that ends when \sestab is reached. \sfwone, \sfwtwo, \sclosing, and \stimewait are a group of states that represents waiting for a connection termination request from remote TCP. \sclosew and \slastack represent waiting for a connection termination request from the local user. Finally, \sclosed represents no connection state at all.

%\subsection{TCP Multitasking model}

TCP is based on a multitasking model. Different tasks can interact and update the socket data structure, used to retain the status of a TCP connection, to handle the various events that can occur within a TCP session. The TCP norm, \cite{rfc793} , under Section "3.9. Event Processing" page 52, describes a possible implementation of how to handle these events based on three tasks: one for the \emph{user calls}, one for the \emph{arriving segments} and one for the \emph{timers}. The role of each of the three tasks can be summarized as follow: User calls refer to functions, namely \texttt{open}, \texttt{close}, \texttt{abort}, \texttt{send} and \texttt{receive}, that can be called by the user to control the connection, send, or receive data. These functions can trigger transitions between the connection's states since they are intended to control the connection. In the arriving segments task, the received segments are being processed,
and the corresponding messages are sent back. Transitions between states can be triggered on the reception of a segment. Finally, timers control the timeouts, for example, the retransmission timeout to retransmit a message or the time-wait timeout to close the connection after a specified amount of time elapsed. Thus, corresponding transitions to the timeout events can also be triggered by this task. A complete description of the protocol's specification can be found at the \emph{RFC 793} document \cite{rfc793}.

The CycloneTCP implementation adopts the three-task-based model and the socket data structure defined by the \cite{rfc793}. Thus, it has tasks dedicated to the user's code, to the timers, and to the processing of the incoming segments. Moreover, the user can manipulate a socket through the TCP's library Application Programming Interface (API) to perform various TCP operations, such as data transmission.

\section{Specification techniques used}
\label{sec:spec}

\subsection{The SPARK programming language}

Ada is a general-purpose, procedural programming language that puts great emphasis on the safety and correctness of the program. Some of the safety characteristics of the language are its strong typing system and its extensive compile-time and runtime checks. Common C programming vulnerabilities like using unsafe pointers or improper null termination of strings can not exist in an Ada program, while issues like buffer overflow or integer overflow can be dynamically captured by Ada’s runtime checks and dealt with via exception handlers. Furthermore, Ada introduced contracts, such as post- and pre-conditions, as part of the language’s standard syntax. Such contracts are vital for explicitly expressing software and verification requirements in the source code to allow for static analyzers or runtime checks to verify that the stated requirements are met.

By subsetting Ada, the SPARK programming language \cite{mccormick_chapin_2015} emerged to provide the largest possible subset of Ada, which is suitable for functional specification and static verification. For instance, in SPARK, expressions should be free from side effects, and aliasing is forbidden (no two variables should share the exact memory location or overlap in memory), including when using pointers thanks to the use of an ownership policy~\cite{dross2020recursive}.

\emph{GNATprove} \cite{GNATProve:users_manual} is the platform that provides formal verification for SPARK through two kinds of analysis. The first enables flow analysis to check the initialization of variables, look at data dependencies between inputs and outputs of subprograms, and detects unused assignments and unmodified variables. The second uses deductive verification to generate verification conditions for SMT solvers via a weakest-precondition calculus to detect possible runtime errors and violations of functional contracts.



\subsection{Interfacing SPARK and C code}

The verification of the entire functional specification of the \emph{CycloneTCP} library is beyond the scope of this work. Instead, the aim is to demonstrate how the use of SPARK can provide significant security hardening to widely used C-written libraries. Thus, this work focuses on the hardening of the TCP library areas that its original authors designated as the most vulnerable or crucial to conform to their functional specifications, namely, the Application Programming Interface (API). This mainly falls under two categories: a)  hardening the user's API to enforce its correct usage by the users, discussed in \Cref{sec:API}, and b) proving the conformance to the protocol's functional specification for the translated code, discussed in \Cref{sec:verif}.

\todo[inline]{KG: fixed up to here}

Hopefully, SPARK integrates a mechanism to interface C code. No verification are
performed on the C code, but pre- and postconditions can be attached to
subprograms and they can be called in SPARK code.
The functional specification are not proved, thus it is the role of the
programmer to ensure the correctness of the contracts.

The types in SPARK can be more expressive than the types in C which adds more
safety to the SPARK code.
But the C and the SPARK code can share objects and it is essential that the
memory representations of an object are the same in the C and in the SPARK side.
For instance, if a C function is supposed to be called with a 32-bits integer,
it is the responsibility of the programmer to ensure that the function is
actually called with a 32-bits integer in the SPARK code.

Interfacing C and SPARK code is a great opportunity to plug our work in an
existing library, but it is also be a source of errors if it is not done
carefully. In section~\ref{sec:verif} it is explain how we have dealt with these
problems to ensure the quality of our work.

\subsection{Dealing with pointers}
\label{sec:pointers}

In CycloneTCP library, pointers are often manipulated at top-level and transmitted
to C functions. They are also used as fields in structures, for instance in
the socket structure to store other complex data-structures and recursive pointer
based data-structures. SPARK use a pointer ownership model to prevent bugs
involving pointers such as memory leak or double free. When a memory area is
allocated, a pointer points to this memory area and thus it is owned.
The ownership of the memory can be moved but the memory must be deallocated
before the end of the execution of the program.

\subsection{Specifying the frame condition}

The socket structure is shared between different functions, and contains a lot
of fields. Most of the fields are used in other parts of library and are not
relevant for our verification. We only need to concentrate on a subset of fields
to make the specifications easier to write, and to understand.
This can be achieved in SPARK by using \emph{models} and \emph{ghost code}
which are used by GNATprove for analysis but not compiled in the final executable.

In the contract, we use the construction \spark{Model(Sock)} to refer the
relevant fields of the object \spark{Sock} where
\spark{Model} is a ghost function that extract the fields of interest from
\spark{Sock}, like in the construction frequently used in postconditions
\begin{lstlisting}[language=Ada, basicstyle=\small\ttfamily]
Model(Sock) = (Model(Sock)'Old with delta
                    State => TCP_STATE_CLOSED)
\end{lstlisting}
that states that relevant fields of \spark{Sock} selected by \spark{Model} are
not changed by the function call, except the fields \spark{State} that is equal
to \spark{TCP_STATE_CLOSED} after the call.

\section{Conformance to the TCP protocol}
\label{sec:verif}

% The reader can refer to the code at \url{https://github.com/AdaCore/Http_Cyclone}.


\subsection{Extracting a specification from the TCP norm}

Extracting a specification
is mandatory to provide functional contracts to the user functions. That can
be achieved by reading the norm. However, the norm is underspecified in many
cases and only one possible implementation is depicted. Thus, the specifications
we have extracted are conformant with the norm but they slightly differ to what
can be found in the RFC.
Among the specification we have extracted:
\begin{itemize}
\item The transitions between the states must respect the order given by the
state machine described in figure~\ref{Fig:statemachine}.
In particular, a transition from a state to
another is valid only if there exists a transition in the state machine between
these two states.
\item The user functions contain functional specifications in the norm, that
have to be done  when a function is called depending on the state of the
socket~\cite[p. 52]{rfc793}. In particular it is specified in what state the
function can be called without returning an error.
\end{itemize}

\subsection{Rewriting the TCP user functions}

The user functions of the TCP protocol have been rewritten in SPARK. Besides
proving the absence of run-time error in these functions, it has been possible
to check that the functional specifications of the TCP protocol are not violated
by the code.

% dire que les fonctions appelées dans le code on était modélisées pour prendre
% en compte les changements d'état TCP qu'elles occasionnent.

% Problème, certains changement d'état se font entre l'appel de deux fonctions,
% ça doit donc être pris en compte. Et certains état se font directement lors de
% l'appel d'une fonction particulière et ça doit aussi être pris en compte.

When a transition has to be made in the code, it is made through the helper
function \spark{TCP_Change_State}. The precondition of this function describes
all the allowed transitions. Therefore, when we try to do a forbidden transition,
GNATprove will display a message. This is the most direct way to make a
transition in the state machine.
As the TCP user functions are all protected with a mutex to avoid interferences
from other threads that could change the TCP state during their execution, in
particular when a new segment is received, it is quite easy to know the
possible set of state that can have the socket during the all execution of the
functions.

There is only one function that makes the verification harder because it
releases the mutex: the function \spark{TCP_Wait_For_Events}.
It takes as argument an event to wait and returns once the event
is triggered by the reception of a segment.
The role of this
function is to release the mutex and allow the reception task to process the
incoming segments. This function
can be used, for example, in the function \spark{open} when the connection
is initialized to wait until the connection has been established or not to
correctly set the error that indicates to the user the state of the connection.
If we consider that everything can happen during a call to \spark{TCP_Wait_For_Events},
the verification becomes too imprecise and it becomes impossible to prove the
functional specifications extracted from the norm. Instead we have decided to
find a better contract to this function.

\subsection{Dealing with synchronous changes of states}

The function \spark{TCP_Wait_For_Events} first checks if the event is not already
true. If not, the mutex is released until a segment that triggered the event is
received or until the timeout is reach. Each time a new segment is received, it
is processed and if it contains a segment that causes a change of state, the TCP
state is updated. Then the events are updated, and if the waited event becomes
true due to the change of state, it is triggered.

\begin{algorithm}[t]
    \caption{Function to compute the possible state after the completion of a
particular event that is requested by a user-task related function.}
\label{algo:waitForEvents}
\begin{algorithmic}[1]
\footnotesize
\Function{TCP\_Wait\_For\_Events\_Proof}{Socket, Event\_Mask}
    \State $S_{last} := \text{Socket}$
    \State $E :=$ \spark{TCP_Update_Events}($S_{last}$)
    \If{$(E\ \&\ \text{Event\_Mask}) \neq 0$}
        \State \textbf{return}  $S_{last}$
    \EndIf
    \For{$i=1$ \textbf{to} $3$}
        \State $S_{last} :=$ \spark{TCP_Process_One_Segment}($S_{last}$)
        \State $E :=$ \spark{TCP_Update_Events}($S_{last}$)
        \If{$(E\ \&\ \text{Event\_Mask}) \neq 0$}
            \State \textbf{return} $S_{last}$
        \EndIf
    \EndFor
    \State \textbf{return} $\emptyset$
\EndFunction
\end{algorithmic}
\end{algorithm}

An event is considered to be true or not depending on the state of the socket.
This computation is done by the function \spark{TCP_Update_Events}. We have put
a contract on it, which is proved to be correct by SPARK. Then we can write a
function that emulates what is done when \spark{TCP_Wait_For_Events} is called.
We have written a procedure \spark{TCP_Wait_For_Events_Proof}, reproduced in
algorithm~\ref{algo:waitForEvents} to compute all the possible TCP states that a
socket can have after a wait. This algorithm simulates the reception of
one message, update the events and return if the event waited is reached.
Otherwise it repeats the procedures. The for loop only requires three steps
because all the step in the state machine can be reached in three segment
receptions without user interaction.

On \spark{TCP_Wait_For_Events_Proof}, a contract has been put to describe all
the possible states that a socket can have after the wait. It is only possible
to prove this contract with SPARK if the function named
\spark{TCP_Process_One_Segment} in algorithm~\ref{algo:waitForEvents}
has a postcondition.

\subsection{Symbolic execution to extract contracts}

Rewriting the part that process the incoming segments was out of the scope of
this work. Instead, we have opted for the use of symbolic execution on the
original CycloneTCP C code.
Symbolic execution is a mean to execute programs with symbolic values rather
than concrete values. Symbolic execution has already been successfully
used with other verification methods.
Indeed, in~\cite{vanoverberghe2008using} the authors present how to use symbolic
execution to improve deductive verification, and in~\cite{kassios2012comparing}
the authors explain that symbolic execution can be good at infering contracts.
For our work, KLEE has been used. It is built on top of LLVM as it takes LLVM
bytecode in input and works well with C code thanks to a very simple interface.

\begin{figure}
\begin{lstlisting}[language=C, basicstyle=\footnotesize\ttfamily, numbers=left,
    numberstyle=\tiny, frame=bottomline, escapeinside={(*@}{@*)}]
// creation of a fake incoming segment
TCPheader *segment = malloc(sizeof(TCPheader));
klee_make_symbolic(segment, sizeof(segment), "seg");
klee_assume(segment->flag <= 31);
// Creation of the socket
Socket *sock = malloc(sizeof(Socket)), oldSock;
klee_make_symbolic(sock, sizeof(sock), "sock");
memcpy(&oldSock, sock, sizeof(Socket));

// The function that process the segments is called
tcpProcessSegment(sock, segment); (*@\label{code:kleedriver:tcpProcessSegment}@*)

// Contract to check
klee_assert( (*@\label{code:kleedriver:assert}@*)
    (oldSock.state == TCP_STATE_ESTABLISHED) ?
        sock.state == TCP_STATE_ESTABLISHED ||
        sock.state == TCP_STATE_CLOSE_WAIT ||
        sock.state == TCP_STATE_CLOSED :
    (oldSock.state == ...) ? ... )
)
\end{lstlisting}
\caption{Driver for the verification of \lstinline[language=C]{tcpProcessSegment}
with KLEE}
\label{code:kleedriver}
\end{figure}

The first step in order to extract contracts was to read the state machine to
know all the possible transitions that can be done by the reception of a flag,
and adapt it to
the subtleties of CycloneTCP. The next step is to write a driver to run KLEE and
know if the contracts that we have infered are correct or not.
A simplified example is shown in figure~\ref{code:kleedriver}. The first lines
create a symbolic incoming segment to process as well as a symbolic socket.
At line~\ref{code:kleedriver:tcpProcessSegment} the function that processes the
segment is called. It is followed at line~\ref{code:kleedriver:assert} by a KLEE
builtin that check if an assert is valid for all the symbolic paths
explored before.

Once the contract is validated by KLEE, it can be copied out on the SPARK
function \spark{TCP_Process_One_Segment}. With this step done, the concurrency
challenge has been solved and the function
\spark{TCP_Wait_For_Events} have a correct and an accurate contract, which
makes possible the verification of the functional correctness of the TCP user
functions thanks to SPARK.



\section{Hardening the user's API}
\label{sec:API}

It appears that lot of programmers do not correctly use the socket API that is
provided by the library. Providing verified user functions for TCP is not enough
to guarantee the safety of software if the users do not correctly use them.
An important part of the work was to ensure that code that uses the socket API's
functions are correctly called. By ``correctly'' we mean: 1)~the functions
are called with respect to a defined order and 2)~the return code is checked
before continuing the processing.

\subsection{Enforcing the correct order of API functions}

The TCP protocol implies a specific order such that the user can call the API's
functions without breaking the functional specification of the protocol. This
order also is being conveyed by the protocol's state machine given in
figure~\ref{Fig:statemachine}.
Ada's pre- and postconditions are a powerful tool to express such inter-function
dependencies, while SPARK technology can be used to guarantee that the
assertions always hold. Thus, pre- and postconditions were introduced to model
a partial order on the calls to the API's functions.

\begin{figure}
\begin{lstlisting}[language=Ada,basicstyle=\footnotesize\ttfamily]
procedure Socket_Connect
   (Sock           : in out Not_Null_Socket;
    Remote_Ip_Addr : in     IpAddr;
    Remote_Port    : in     Port;
    Error          :    out Error_T)
   with
   Pre => Is_Initialized_Ip (Remote_Ip_Addr),
   Post =>
    if Sock.S_Type = SOCKET_TYPE_STREAM then
      (if Error = NO_ERROR then
        Sock.S_Remote_Ip_Addr = Remote_Ip_Addr)
    else
      Sock.S_Remote_Ip_Addr = Remote_Ip_Addr

procedure Socket_Send
   (Sock    : in out Not_Null_Socket;
    Data    : in     Send_Buffer;
    Written :    out Natural;
    Flags   :        Socket_Flags;
    Error   :    out Error_T)
   with
   Pre => Is_Initialized_Ip (Sock.S_Remote_Ip_Addr)
\end{lstlisting}
\caption{An example of how function calls can be ordered by pre- and
postconditions}
\label{fig:functionorder}
\end{figure}

Simplified contracts extracted from our library are reproduced in
figure~\ref{fig:functionorder}. If no error occurs, the function
\spark{Socket_Connect} sets \spark{Sock.S_Remote_Ip_Addr} to
\spark{Remote_Ip_Addr} which is supposed to be
initialized when the function is called. \spark{Socket_Send} requires to be
called with a socket not null such that its field \spark{Remote_Ip_Addr} is
initialized. The only way to ensure that the precondition hold is to
call \spark{Socket_Connect} before \spark{Socket_Send}.
The tool GNATprove can statically find if a call to \spark{Socket_Send}
is not preceded by a call to \spark{Socket_Connect}.

\subsection{Checking the correctness of return codes}

A common mistake is to forget to check the return codes after a call to a socket
API's function. For instance, the following code would be reject by SPARK:
\begin{lstlisting}[language=Ada,basicstyle=\small\ttfamily]
Socket_Connect(Sock, Ip_Addr, Port, Error);
Socket_Send(Sock, Data, Written, Flags, Error);
\end{lstlisting}
Indeed, if \spark{Socket_Connect} fails and \spark{Error} is not equal to
\spark{NO_ERROR}, \spark{Sock.S_Remote_Ip_Addr} might be non initialized, and
then the function \spark{Socket_Send} cannot be called because of its
precondition.

\section{Results}
\label{sec:results}

\subsection{Bugs found}

\subsubsection{Memory leak}

Thanks to the pointer ownership policy adopted by SPARK and detailed in
section~\ref{sec:pointers}, we have found that a memory leak can happen when
the connection have been closed and the buffer are cleaning.

\subsubsection{Violation of the TCP protocol}

Another very interesting and very subtle bug have been found thanks to SPARK is
reproduced in the snippet bellow.

\begin{lstlisting}[language=Ada, basicstyle=\footnotesize\ttfamily,
                    numbers=left, numberstyle=\tiny, escapechar=\%]
case Sock.State is
  when TCP_STATE_SYN_RECEIVED
     | TCP_STATE_ESTABLISHED =>
  -- Flush the send buffer
  TCP_Send (Sock, Buf, Ignore_Written,
            SOCKET_FLAG_NO_DELAY, Error);
  if Error /= NO_ERROR then
      return;
  end if;

  -- Make sure all the data has been sent out
  TCP_Wait_For_Events % \label{bugProg:tcpWaitForEvents} %
     (Sock       => Sock,
      Event_Mask => SOCKET_EVENT_TX_DONE,
      Timeout    => Sock.S_Timeout,
      Event      => Event);

  -- Timeout error?
  if Event /= SOCKET_EVENT_TX_DONE then
     Error := ERROR_TIMEOUT;
     return;
  end if;

  -- Send a FIN segment
  TCP_Send_Segment   % \label{bugProg:tcpWaitForEventsPost} %
     (Sock         => Sock,
      Flags        => TCP_FLAG_FIN or TCP_FLAG_ACK,
      Seq_Num      => Sock.sndNxt,
      Ack_Num      => Sock.rcvNxt,
      Length       => 0,
      Add_To_Queue => True,
      Error        => Error);

  -- Failed to send FIN segment?
  if Error /= NO_ERROR then
     return;
  end if;

  -- Switch to the FIN-WAIT-1 state
  TCP_Change_State (Sock, TCP_STATE_FIN_WAIT_1); % \label{bugProg:tcpChangeState} %
\end{lstlisting}

In this scenario, after the call to \spark{Tcp_Send}, when the error cases have
been filter, the state of the socket can either be \sestab or \sclosew. The call
at line~\ref{bugProg:tcpWaitForEvents} and now the state of the socket can be
still be \sestab or \sclosew, or if a \rst flag has been received when the mutex
was released, the state can be \sclosed too.
At line~\ref{bugProg:tcpWaitForEventsPost}, a \fin segment is sent, which does
not modify the state of the socket. Finally, at line~\ref{bugProg:tcpChangeState}
we try to jump to the state \sfwone and thus the transitions $\text{\sclosew}
\rightarrow \text{\sfwone}$ and $\text{\sclosed} \rightarrow \text{\sfwone}$ are
possible.

But these transition are not allowed by the norm, and thus not allowed by the
precondition of \spark{TCP_Change_State}. The problem is detected by SPARK and a fix
has been proposed.


\subsection{Verified parts}

For achieving this verification, 50 subprograms have been translated from C to
SPARK. This accounts for \np{2266} lines of code of which \np{1165} are logical
code to write and prove the specifications.

\section{Conclusion and future work}

The use of SPARK for the verification of the TCP protocol has given good
results. It has helped to find bugs in the existing implementation. But more
than finding bugs, the interest of this work lie in the face that it is a big
step toward a secure implementation. It has been proved by the tool GNATprove
that our implementation is free of run-time errors and that all the transitions
in the TCP state machine are done with respect to the norm.

However weeknesses exist in our implementation, in particular because all the
underlying layers are still written in C. The principal function of those layers
is to format packet before they are sent, or parse incoming packets, check their
integrity and transmit the resulting payload to the corresponding upper level
layer. This processing part can be a source of errors and bugs as explain
in~\cite{Reiher2019RecordFluxFM}.
Using the RecordFlux DSL to parse the packets of the different protocols is the
next step to make the stack safer. Using RecordFlux to parse TCP message
would be a big step to finish the translation of the TCP protocol in SPARK.
The postconditions extracted by KLEE could be proved by GNATprove for a
safer result.

Our verification of the TCP protocol only focuses on the validity of the
transitions in the TCP state machine, but some other properties are formulated
in the TCP norm, and could be verified in the implementation to make it even
more robust.

\bibliographystyle{IEEEtran}
\bibliography{biblio}

\end{document}
